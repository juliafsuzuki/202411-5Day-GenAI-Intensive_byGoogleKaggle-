![image](https://github.com/user-attachments/assets/6bbbc492-345f-4627-9c4e-93ae4268c76f)

ðŸ‘‹ Hello - 

I completed the 5-Day Gen AI Intensive course offered by Google + Kaggle and documented my learning here in this GitHub repository. 

1. Gen AI Intensive Course Curriculum: [Link](https://www.kaggle.com/learn-guide/5-day-genai#GenAI)
- Foundational LLMs & Prompt Engineering
- Embeddings & Vector databases
- Generative Agents
- Domain-specific LLMs
 - MLOps for Generative AI 

2. Kaggle notebooks (links below); I've updated the original tutorial notebooks by experimenting with my own data.

Resources:
- About the course: [Link](https://rsvp.withgoogle.com/events/google-generative-ai-intensive)
- YouTube Playlist: [Link](https://www.youtube.com/playlist?list=PLqFaTIg4myu-b1PlxitQdY0UYIbys-2es)

-----

**Day 1**: Foundational Large Language Models, Text Generation, & Prompt Engineering

Learning Objective:
Explore the evolution of LLMs, from transformers to techniques like fine-tuning and inference acceleration. Get trained with the art of prompt engineering for optimal LLM interaction.

Kaggle Notebook:
1. Learn prompting fundamentals: [Link](https://www.kaggle.com/code/juliasuzuki/day-1-llm-prompt-engineering) 

-----

**Day 2**: Embeddings and Vector Stores/Databases 

Learning Objective:
Learn about the conceptual underpinning of embeddings and vector databases, including embedding methods, vector search algorithms, and real-world applications with LLMs, as well as their tradeoffs.

Kaggle Notebooks:
1. Build a RAG question-answering system over custom documents: [Link](https://www.kaggle.com/code/juliasuzuki/day-2-document-q-a-with-rag?scriptVersionId=208487745)
2. Explore text similarity with embeddings: [Link](https://www.kaggle.com/code/juliasuzuki/day-2-embeddings-and-similarity-scores)
3. Build a neural classification network with Keras using embeddings: [Link](https://www.kaggle.com/code/juliasuzuki/day-2-classifying-embeddings-with-keras)

-----

**Day 3**: Generative AI Agents  

Learning Objective:
Learn to build sophisticated AI agents by understanding their core components and the iterative development process.

Kaggle Notebooks:
1. Talk to a database with function calling: [Link](https://www.kaggle.com/code/juliasuzuki/day-3-function-calling-with-the-gemini-api#Try-it!)
2. Build an agentic ordering system in LangGraph: [Link](https://www.kaggle.com/code/juliasuzuki/day-3-building-an-agent-with-langgraph?scriptVersionId=208901539)

-----

**Day 4**: Domain-Specific LLMs 

Learning Objective:
Delve into the creation and application of specialized LLMs like SecLM and Med-PaLM, with insights from the researchers who built them.

Kaggle Notebooks:
1. Ground with Google Search: [Link](https://www.kaggle.com/code/juliasuzuki/day-4-google-search-grounding?scriptVersionId=209213838)
2. Use Gemini API to fine-tune a custom, task-specific model: [Link](https://www.kaggle.com/code/juliasuzuki/day-4-fine-tuning-a-custom-model?scriptVersionId=209221544)

-----

**Day 5**: Gemini API Features 

Learning Objective: Learn extra Gemini API features (bonus lesson)

Kaggle Notebook:
1. Extra Gemini API Features: [Link](https://www.kaggle.com/code/juliasuzuki/bonus-day-extra-gemini-api-features?scriptVersionId=209226299)

-----

![20241123 - 5 Day Gen AI Intensive Course Completed](https://github.com/user-attachments/assets/d7bc8d09-a2df-46e2-a000-1d9957aa88db)
